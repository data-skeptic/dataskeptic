# 2016-02-23 Minutes

Progress made so far has been setting up an early prototype API written in Python with Django Framework.  

## Data model discussion

We talked about finalizing the data model, a necessary next step to make next steps on the API.  Kyle presented some discussion around the format of RESO (Real Estate Standards Organization).  Their format can be found [here](https://reso.memberclicks.net/assets/Certifications/resodatadictionarycertificationoverview_v1.4.0_2015_0723.pdf).  After some discussion, it was decided that a less heavy handed solution would probably be better.

Previously, discussion in the Slack channel and a PR was sent containing some suggestions.  A central theme of the proposed design was a limited number of strongly typed data points (number of bedrooms, bathrooms, sqft, etc.) would be included and then a general "Feature" attribute.

During the discussion, it was commented that including the "units" of each feature and some sort of official "status" would be good properties.  In this respect, any user can push any property they think is relevant.  As we converge on properties that have canonical values, less official status, can have mapping bots that convert the various formats to a more standardized data representation.

## Persistence layer

Based on numerous comments, most notably, the availability of widely used geo-spacial tools for both Postgres and Django gives us confidence that Postgres is a smart data store for this project.

## Misc

It was agreed that we would use github issues to track feature requests and bugs, at least for now.

Inspired by Mike Bostock's work, when data becomes available we shall put effort into encouraging contributors to create visualizations of this data and host a standardized gallery of them.

Lastly, a comment was raised pointing out that we don't have an efficient mechanism for people to announce data sources they are exploring, to notating when they tried various sources that may not have amounted to anything.  Thus, contributors could either do double duty (both explore the same path) or retrace old steps (if the path is a dead end).  This topic will be raised again next week after people have time to ponder how we might centralize this metadata.

## Next Steps

One attendee volunteered to write up a JSON Schema formal description of the proposed data model for review next session.

Kyle mentioned he is looking for someone that has a deep familiarity with the various open licenses (MIT, Creative Commons, Gnu, etc.) to present options to the community about how both the code and the data collected might be licensed.  This issue should probably be decided before the API accepts uploads, so that all contributors understand how their contributions might later be used.

Kyle will also set up a Postgres database for the project in the next day or two.

Further API development will continue as well.

