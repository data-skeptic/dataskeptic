<? include("../header.php") ?>

<div id="bbody">
<h1>Contest</h1>

<p>As announced on the recent update posted to the podcast feed, The Data Skeptic Podcast is launching a contest- not one of chance, but one of skill.  Listeners are encouraged to put their data science skills to good use, or if all else fails, guess!</p>

<p>The contest works as follows.  Below is some data about the cumulative number of downloads the podcast has achieved on a few given dates.  Your job is to predict the date and time at which the podcast will recieve download number 27,182.  Why this arbitrary number?  It's as good as any other arbitrary number!</p>

<!--begin.rcode echo=FALSE, fig.align='center'
dates = as.POSIXct(c("2014-06-21", "2014-07-31", "2014-08-30", "2014-10-04"))
dateNums = as.numeric((dates - dates[1]) / 60 / 60 / 24)
downloads = c(130, 2313, 6146, 13400)

data = data.frame(dates=dates, dateNums=dateNums, downloads=downloads)

end.rcode-->
<!--begin.rcode fig.align='center'
data
end.rcode-->

<p>Use whatever means you want to formulate a prediction.  Once you have it, wait until that time and then post a review of the Data Skeptic Podcast on iTunes.  You don't even have to leave a good review!  The review which is posted closest to the actual time at which this download occurs will win a free copy of Matthew Russell's "Mining the Social Web" courtesy of the Data Skeptic Podcast.  "Price is Right" rules are in play - the winner is the person that posts their review closest to the actual time without going over.</p>

<p>The plot below reveals the four data points you are being given to help inform your prediction.</p>

<!--begin.rcode echo=FALSE, fig.align='center'
goal = floor(exp(1) * 10^4)

plot(data$dateNums, data$downloads, xlab="time", ylab="cumulative downloads", axes=FALSE, ylim=c(0, 1.1*max(downloads)))
axis(1, at=data$dateNums, labels=data$dates)
axis(2)
end.rcode-->

<p>What type of curve do you think best fits this data? Linear? Exponential? Logarithmic? Let's experiment with linear for an example.  The plot above expresses the data with time on the x axis.  Since we're actually trying to <i>predict</i> the time for a known number of downloads (y axis), let's invert this chart for the next few steps.</p>

<!--begin.rcode fig.width=7, fig.height=6, echo=FALSE, fig.align='center'
lmfit = lm(dateNums ~ downloads, data)

goalDf = data.frame(dateNums=NA, downloads=goal)
prediction = predict(lmfit, goalDf)
params = coef(lmfit)

plot(data$downloads, data$dateNums, xlab="downloads", ylab="days", ylim=c(0, 1.2*prediction), xlim=c(0, 1.2*goal), axes=FALSE)
axis(1)
axis(2)
abline(lmfit)
abline(h=prediction, lty=2)
abline(v=goal, lty=2)
text(0, prediction*1.04, "prediction", pos=4)
text(goal*0.95, prediction/2, "goal", srt=90)

predictionDt = data[1,"dates"] + prediction*60*60*24
end.rcode-->

<p>If this linear fit is correct, it suggests the winning time to post a review is <!--rinline predictionDt -->.  But might some other curve fit better?  The eye naturally looks like there's some exponential growth here.  So perhaps we should try to take the logarithm of the number of downloads so that the proposed exponential growth is transformed into a linear relationship.</p>

<!--begin.rcode fig.width=7, fig.height=6, echo=FALSE
lmfit = lm(dateNums ~ log(downloads), data)

goalDf = data.frame(dateNums=NA, downloads=goal)
prediction = predict(lmfit, goalDf)
params = coef(lmfit)

plot(log(data$downloads), data$dateNums, xlab="log(downloads)", ylab="days", ylim=c(0, 1.2*prediction), xlim=c(0, 1.2*log(goal)), axes=FALSE)
axis(1)
axis(2)
abline(lmfit)
abline(h=prediction, lty=2)
abline(v=log(goal), lty=2)
text(0, prediction*1.04, "prediction", pos=4)
text(log(goal)*0.95, prediction/2, "goal", srt=90)

predictionDt = data[1,"dates"] + prediction*60*60*24

end.rcode-->

<p>By this analysis, we find the goal reached at <!--rinline predictionDt -->.  Not true, that date is passed!  What's gone wrong here?  Should you give up or try a different line of inquiry?  This model is clearly a bad one, but it does teach us something important.  The growth rate is upper bounded by this log-linear regression - a good model will be more conservative than this.</p>

<p>On the podcast I suggested perhaps exploring another type of approach.  The total number of downloads could be decomposed into two separate phenomenon.  First, there is always a spike in downloads on the day of a new episode being released.  Second, there is a "background noise" of daily downloads that are likely generated by new listeners, casual dabblers, and subscribers exploring the back catalog.  Might an equation like this work?</p>

$$D(t) = m_b \cdot t + m_r \cdot \Big\lfloor \frac{t}{7} \Big\rfloor + b$$

<p>where $D$ is the total downloads, $t$ is the day, $m_b$ is the rate of background downloads, $m_r$ is the rate of downloads on release days, and $b$ is the y intercept.

</div>

 <script type="text/javascript" 
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script type="text/javascript">MathJax.Hub.Config({tex2jax: {processEscapes: true, 
        processEnvironments: false, inlineMath: [ ['$','$'] ], 
        displayMath: [ ['$$','$$'] ] }, 
        asciimath2jax: {delimiters: [ ['$','$'] ] }, 
        "HTML-CSS": {minScaleAdjust: 125 } });
    </script>

<? include("../footer.php") ?>
