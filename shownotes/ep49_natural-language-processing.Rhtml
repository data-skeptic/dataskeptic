<? include("../header.php") ?>

<div id="bbody">

<h1>Natural Language Processing</h1>

<p>This episode overviews some of the fundamental concepts of natural language processing including stemming, n-grams, part of speech tagging, and the
bag of words approach.</p>

<h2>Feedback</h2>
<p>I got some great feedback on this episode from 
<a href="https://twitter.com/psygnisfive">Darryl McAdams (@psygnisfive)</a>.  I wanted to include his comments in the show notes for future listeners.</p>

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/DataSkeptic">@DataSkeptic</a> i think in part it *is* the speed of the chips tho. if you can&#39;t process 10M hours of audio in reasonable time, you&#39;re hosed</p>&mdash; Darryl McAdams (@psygnisfive) <a href="https://twitter.com/psygnisfive/status/589572507469877248">April 18, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>For speech signal processing, certainly faster CPUs and even the emergence of GPU calculations have probably had the most impact.  For natural language processing,
however, I think memory and distributed computing have been more impactful.  I'm reminded of the seminal work
<a href="http://research.microsoft.com/pubs/66840/acl2001.pdf">Scaling to Very Very Large Corpora for Natural Language Disambiguation</a> by Brill and Banko
at Microsoft Research which showed that large training corpora was more effective than better algorithms for natural language understanding.
While certainly, CPU made their training faster, offline training can be patient so long as online recognition is fast.  You'll notice they
don't even mention training time on the axis of any of their figures.</p>

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/DataSkeptic">@DataSkeptic</a> regarding &quot;the&quot;, it&#39;s an article/determiner. regarding german, it&#39;s SOV (not OVS) by default, but has some extra stuff</p>&mdash; Darryl McAdams (@psygnisfive) <a href="https://twitter.com/psygnisfive/status/589574059576283136">April 18, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Great correction, thank you!  There was a glimmer of doubt for me as I said this, so I'm glad to have more knowledgable listeners to set the record straight.</p>

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/DataSkeptic">@DataSkeptic</a> additionally, OVS is one of the rarest word orders, and might not even exist, it&#39;s not clear</p>&mdash; Darryl McAdams (@psygnisfive) <a href="https://twitter.com/psygnisfive/status/589574359439683584">April 18, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>Really interesting, too.</p>


<? include("../footer.php"); ?>
